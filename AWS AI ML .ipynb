{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"DaJmyayVik2V"},"outputs":[],"source":["# Imports here\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import numpy as np\n","from torch import nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms, models\n","from PIL import Image\n","from collections import OrderedDict\n","import json\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44794,"status":"ok","timestamp":1707464848105,"user":{"displayName":"Sujatha","userId":"02387936916712154920"},"user_tz":-330},"id":"lOHQjutmozYZ","outputId":"d43905dd-2117-4821-d3dc-efc102119cc3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Gvk4w39ifSI"},"outputs":[],"source":["data_dir = '/content/drive/MyDrive/DATASET'\n","train_dir= data_dir + '/train'\n","val_dir= data_dir + '/valid'\n","test_dir = data_dir + '/test'\n","using_gpu = torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-eNHC0VfoYFc"},"outputs":[],"source":["def manual_seed(random_seed: int = 42) -> None:\n","    '''\n","    For maintaining reproducibility of a notebook cell.\n","    '''\n","    # for non-cuda\n","    torch.manual_seed(random_seed)\n","    # in case cuda exists\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(random_seed)\n","\n","# creating device agnostic code\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# clearing cache if using GPU\n","if str(device) == \"cuda\":\n","    torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NfxJsLsw7WA1"},"outputs":[],"source":["BATCH_SIZE = 32\n","LEARNING_RATE = 2e-4\n","EPOCHS = 15\n","HIDDEN_LAYER_1 = 256\n","HIDDEN_LAYER_2 = 128"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5265,"status":"ok","timestamp":1707466521925,"user":{"displayName":"Sujatha","userId":"02387936916712154920"},"user_tz":-330},"id":"zJ72CfYb7zay","outputId":"fed1f1ee-10fa-4c09-cd9b-c2c3770a5f18"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n","Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.1.0+cu121)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2.1.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchvision) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n"]}],"source":["!pip install torchvision"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1743,"status":"ok","timestamp":1707466550952,"user":{"displayName":"Sujatha","userId":"02387936916712154920"},"user_tz":-330},"id":"HyKpdMmw7WFK","outputId":"af9728c4-9c09-493b-883a-d18c76c4bae9"},"outputs":[{"name":"stdout","output_type":"stream","text":["ImageClassification(\n","    crop_size=[224]\n","    resize_size=[256]\n","    mean=[0.485, 0.456, 0.406]\n","    std=[0.229, 0.224, 0.225]\n","    interpolation=InterpolationMode.BILINEAR\n",")\n"]},{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n","100%|██████████| 83.3M/83.3M [00:01<00:00, 84.8MB/s]\n"]}],"source":["import torchvision\n","resnet_34_weights = torchvision.models.ResNet34_Weights.DEFAULT     # DEFAULT will give you the best possible weights\n","\n","# we can look at the transforms used for training the given weights for this network architecture\n","resnet_34_default_transforms = resnet_34_weights.transforms()\n","\n","# checking transforms\n","print(resnet_34_default_transforms)\n","\n","# creating ResNet-34 architecture using the weights specified above\n","model = torchvision.models.resnet34(weights = resnet_34_weights)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6970,"status":"ok","timestamp":1707466686863,"user":{"displayName":"Sujatha","userId":"02387936916712154920"},"user_tz":-330},"id":"SIc4G6qj7jYp","outputId":"8900187a-377b-4804-ca56-a87829dcc108"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n"]},{"data":{"text/plain":["================================================================================================================================================================\n","Layer (type (var_name))                  Input Shape          Output Shape         Param #              Kernel Shape         Mult-Adds            Trainable\n","================================================================================================================================================================\n","ResNet (ResNet)                          [1, 3, 224, 224]     [1, 1000]            --                   --                   --                   True\n","├─Conv2d (conv1)                         [1, 3, 224, 224]     [1, 64, 112, 112]    9,408                [7, 7]               118,013,952          True\n","├─BatchNorm2d (bn1)                      [1, 64, 112, 112]    [1, 64, 112, 112]    128                  --                   128                  True\n","├─ReLU (relu)                            [1, 64, 112, 112]    [1, 64, 112, 112]    --                   --                   --                   --\n","├─MaxPool2d (maxpool)                    [1, 64, 112, 112]    [1, 64, 56, 56]      --                   3                    --                   --\n","├─Sequential (layer1)                    [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --                   --                   True\n","│    └─BasicBlock (0)                    [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --                   --                   True\n","│    │    └─Conv2d (conv1)               [1, 64, 56, 56]      [1, 64, 56, 56]      36,864               [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]      [1, 64, 56, 56]      128                  --                   128                  True\n","│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 64, 56, 56]      [1, 64, 56, 56]      36,864               [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]      [1, 64, 56, 56]      128                  --                   128                  True\n","│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --                   --                   --\n","│    └─BasicBlock (1)                    [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --                   --                   True\n","│    │    └─Conv2d (conv1)               [1, 64, 56, 56]      [1, 64, 56, 56]      36,864               [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]      [1, 64, 56, 56]      128                  --                   128                  True\n","│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 64, 56, 56]      [1, 64, 56, 56]      36,864               [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]      [1, 64, 56, 56]      128                  --                   128                  True\n","│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --                   --                   --\n","│    └─BasicBlock (2)                    [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --                   --                   True\n","│    │    └─Conv2d (conv1)               [1, 64, 56, 56]      [1, 64, 56, 56]      36,864               [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]      [1, 64, 56, 56]      128                  --                   128                  True\n","│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 64, 56, 56]      [1, 64, 56, 56]      36,864               [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]      [1, 64, 56, 56]      128                  --                   128                  True\n","│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --                   --                   --\n","├─Sequential (layer2)                    [1, 64, 56, 56]      [1, 128, 28, 28]     --                   --                   --                   True\n","│    └─BasicBlock (0)                    [1, 64, 56, 56]      [1, 128, 28, 28]     --                   --                   --                   True\n","│    │    └─Conv2d (conv1)               [1, 64, 56, 56]      [1, 128, 28, 28]     73,728               [3, 3]               57,802,752           True\n","│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]     [1, 128, 28, 28]     256                  --                   256                  True\n","│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 128, 28, 28]     [1, 128, 28, 28]     147,456              [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]     [1, 128, 28, 28]     256                  --                   256                  True\n","│    │    └─Sequential (downsample)      [1, 64, 56, 56]      [1, 128, 28, 28]     8,448                --                   6,422,784            True\n","│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --                   --                   --\n","│    └─BasicBlock (1)                    [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --                   --                   True\n","│    │    └─Conv2d (conv1)               [1, 128, 28, 28]     [1, 128, 28, 28]     147,456              [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]     [1, 128, 28, 28]     256                  --                   256                  True\n","│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 128, 28, 28]     [1, 128, 28, 28]     147,456              [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]     [1, 128, 28, 28]     256                  --                   256                  True\n","│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --                   --                   --\n","│    └─BasicBlock (2)                    [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --                   --                   True\n","│    │    └─Conv2d (conv1)               [1, 128, 28, 28]     [1, 128, 28, 28]     147,456              [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]     [1, 128, 28, 28]     256                  --                   256                  True\n","│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 128, 28, 28]     [1, 128, 28, 28]     147,456              [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]     [1, 128, 28, 28]     256                  --                   256                  True\n","│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --                   --                   --\n","│    └─BasicBlock (3)                    [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --                   --                   True\n","│    │    └─Conv2d (conv1)               [1, 128, 28, 28]     [1, 128, 28, 28]     147,456              [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]     [1, 128, 28, 28]     256                  --                   256                  True\n","│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 128, 28, 28]     [1, 128, 28, 28]     147,456              [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]     [1, 128, 28, 28]     256                  --                   256                  True\n","│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --                   --                   --\n","├─Sequential (layer3)                    [1, 128, 28, 28]     [1, 256, 14, 14]     --                   --                   --                   True\n","│    └─BasicBlock (0)                    [1, 128, 28, 28]     [1, 256, 14, 14]     --                   --                   --                   True\n","│    │    └─Conv2d (conv1)               [1, 128, 28, 28]     [1, 256, 14, 14]     294,912              [3, 3]               57,802,752           True\n","│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]     [1, 256, 14, 14]     512                  --                   512                  True\n","│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 256, 14, 14]     [1, 256, 14, 14]     589,824              [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]     [1, 256, 14, 14]     512                  --                   512                  True\n","│    │    └─Sequential (downsample)      [1, 128, 28, 28]     [1, 256, 14, 14]     33,280               --                   6,423,040            True\n","│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   --\n","│    └─BasicBlock (1)                    [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   True\n","│    │    └─Conv2d (conv1)               [1, 256, 14, 14]     [1, 256, 14, 14]     589,824              [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]     [1, 256, 14, 14]     512                  --                   512                  True\n","│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 256, 14, 14]     [1, 256, 14, 14]     589,824              [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]     [1, 256, 14, 14]     512                  --                   512                  True\n","│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   --\n","│    └─BasicBlock (2)                    [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   True\n","│    │    └─Conv2d (conv1)               [1, 256, 14, 14]     [1, 256, 14, 14]     589,824              [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]     [1, 256, 14, 14]     512                  --                   512                  True\n","│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 256, 14, 14]     [1, 256, 14, 14]     589,824              [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]     [1, 256, 14, 14]     512                  --                   512                  True\n","│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   --\n","│    └─BasicBlock (3)                    [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   True\n","│    │    └─Conv2d (conv1)               [1, 256, 14, 14]     [1, 256, 14, 14]     589,824              [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]     [1, 256, 14, 14]     512                  --                   512                  True\n","│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 256, 14, 14]     [1, 256, 14, 14]     589,824              [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]     [1, 256, 14, 14]     512                  --                   512                  True\n","│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   --\n","│    └─BasicBlock (4)                    [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   True\n","│    │    └─Conv2d (conv1)               [1, 256, 14, 14]     [1, 256, 14, 14]     589,824              [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]     [1, 256, 14, 14]     512                  --                   512                  True\n","│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 256, 14, 14]     [1, 256, 14, 14]     589,824              [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]     [1, 256, 14, 14]     512                  --                   512                  True\n","│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   --\n","│    └─BasicBlock (5)                    [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   True\n","│    │    └─Conv2d (conv1)               [1, 256, 14, 14]     [1, 256, 14, 14]     589,824              [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]     [1, 256, 14, 14]     512                  --                   512                  True\n","│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 256, 14, 14]     [1, 256, 14, 14]     589,824              [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]     [1, 256, 14, 14]     512                  --                   512                  True\n","│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   --\n","├─Sequential (layer4)                    [1, 256, 14, 14]     [1, 512, 7, 7]       --                   --                   --                   True\n","│    └─BasicBlock (0)                    [1, 256, 14, 14]     [1, 512, 7, 7]       --                   --                   --                   True\n","│    │    └─Conv2d (conv1)               [1, 256, 14, 14]     [1, 512, 7, 7]       1,179,648            [3, 3]               57,802,752           True\n","│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]       [1, 512, 7, 7]       1,024                --                   1,024                True\n","│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 512, 7, 7]       [1, 512, 7, 7]       2,359,296            [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]       [1, 512, 7, 7]       1,024                --                   1,024                True\n","│    │    └─Sequential (downsample)      [1, 256, 14, 14]     [1, 512, 7, 7]       132,096              --                   6,423,552            True\n","│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --                   --                   --\n","│    └─BasicBlock (1)                    [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --                   --                   True\n","│    │    └─Conv2d (conv1)               [1, 512, 7, 7]       [1, 512, 7, 7]       2,359,296            [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]       [1, 512, 7, 7]       1,024                --                   1,024                True\n","│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 512, 7, 7]       [1, 512, 7, 7]       2,359,296            [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]       [1, 512, 7, 7]       1,024                --                   1,024                True\n","│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --                   --                   --\n","│    └─BasicBlock (2)                    [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --                   --                   True\n","│    │    └─Conv2d (conv1)               [1, 512, 7, 7]       [1, 512, 7, 7]       2,359,296            [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]       [1, 512, 7, 7]       1,024                --                   1,024                True\n","│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 512, 7, 7]       [1, 512, 7, 7]       2,359,296            [3, 3]               115,605,504          True\n","│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]       [1, 512, 7, 7]       1,024                --                   1,024                True\n","│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --                   --                   --\n","├─AdaptiveAvgPool2d (avgpool)            [1, 512, 7, 7]       [1, 512, 1, 1]       --                   --                   --                   --\n","├─Linear (fc)                            [1, 512]             [1, 1000]            513,000              --                   513,000              True\n","================================================================================================================================================================\n","Total params: 21,797,672\n","Trainable params: 21,797,672\n","Non-trainable params: 0\n","Total mult-adds (G): 3.66\n","================================================================================================================================================================\n","Input size (MB): 0.60\n","Forward/backward pass size (MB): 59.82\n","Params size (MB): 87.19\n","Estimated Total Size (MB): 147.61\n","================================================================================================================================================================"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["# using torchinfo to inspect the network\n","!pip install torchinfo\n","from torchinfo import summary\n","summary(model,\n","        input_size=(1,3,224,224),\n","        col_names=(\"input_size\",\n","                   \"output_size\",\n","                   \"num_params\",\n","                   \"kernel_size\",\n","                   \"mult_adds\",\n","                   \"trainable\"),\n","        col_width=20,\n","        row_settings=(\"var_names\",))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VQOzLRC67WI6"},"outputs":[],"source":["train_transforms = transforms.Compose([transforms.Resize(size=(256,256),\n","                                                         interpolation=transforms.InterpolationMode.BILINEAR),\n","                                       transforms.TrivialAugmentWide(interpolation = transforms.InterpolationMode.BILINEAR),\n","                                       transforms.CenterCrop(size=(224,224)),\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                                            std=[0.229, 0.224, 0.225])])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5967,"status":"ok","timestamp":1707467115870,"user":{"displayName":"Sujatha","userId":"02387936916712154920"},"user_tz":-330},"id":"cos9su1k-GZW","outputId":"8480255c-daf3-435c-ccf7-60810a3f6f38"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pathlib in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"]}],"source":["!pip install pathlib\n","from pathlib import Path"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Gmi7aIFu8sF1"},"outputs":[],"source":["# 1. training dataset\n","\n","\n","\n","\n","train_dataset = torchvision.datasets.ImageFolder(root = str(data_dir / Path('train')),\n","                                        transform=train_transforms)\n","\n","# 2. validation dataset\n","val_dataset = torchvision.datasets.ImageFolder(root = str(data_dir / Path('valid')),\n","                                      transform=resnet_34_default_transforms)\n","\n","# extracting number of classes and class_to_idx mapping\n","CLASSES = train_dataset.classes\n","NUM_CLASSES = len(CLASSES)\n","CLASS_TO_IDX = train_dataset.class_to_idx"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1045,"status":"ok","timestamp":1707467279507,"user":{"displayName":"Sujatha","userId":"02387936916712154920"},"user_tz":-330},"id":"c3fvcCom8sJh"},"outputs":[],"source":["# creating dataloaders\n","!pip install os\n","import os\n","# 1. training set dataloader\n","train_loader = torch.utils.data.DataLoader(train_dataset,\n","                                           batch_size = BATCH_SIZE,\n","                                           shuffle=True,\n","                                           num_workers=os.cpu_count() if str(device) == \"cuda\" else 0,      # if you have GPU it makes sense to spin up multiple worker processes to fetch data batches, num_workers=<cpu cores> is a good rule of thumb (https://stackoverflow.com/a/54002191)\n","                                           pin_memory=True if str(device) == \"cuda\" else False)             # if you have GPU it almost always makes sense to have 'pin_memory = True', as this makes the data transfer to GPU more efficient (https://discuss.pytorch.org/t/when-to-set-pin-memory-to-true/19723/2)\n","\n","# 2. validation set dataloader\n","val_loader = torch.utils.data.DataLoader(val_dataset,\n","                                         batch_size = BATCH_SIZE,\n","                                         shuffle=False,\n","                                         num_workers=os.cpu_count() if str(device) == \"cuda\" else 0,\n","                                         pin_memory=True if str(device) == \"cuda\" else False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":547,"output_embedded_package_id":"1vv5JYIHZTcoSMQ2dNcmw3Qi9YVmZW_t_"},"executionInfo":{"elapsed":81244,"status":"ok","timestamp":1707467379846,"user":{"displayName":"Sujatha","userId":"02387936916712154920"},"user_tz":-330},"id":"lRqcv_e9-w58","outputId":"7a6949da-4e4d-4e5c-ec85-dbc340c1593c"},"outputs":[],"source":["def denormalize_and_clip(img, mean, std):\n","    img = img.numpy(force=True) if isinstance(img, torch.Tensor) else img\n","    img = np.transpose(img, (1, 2, 0))\n","\n","    # Denormalize and clip values to stay in the valid range [0, 1]\n","    img = std * img + mean\n","    img = np.clip(img, 0, 1)\n","    return img\n","\n","def imshow(img, title):\n","    plt.imshow(img)\n","    plt.title(title)\n","    plt.axis('off')  # Remove ticks and axes\n","    plt.show()\n","\n","def visualize_random_batch(data_loader, loader_type, mean, std):\n","    # Get a random batch index\n","    batch_index = np.random.randint(len(data_loader))\n","\n","    # Get the random batch from the data loader\n","    for i, (images, labels) in enumerate(data_loader):\n","        if i == batch_index:\n","            break\n","\n","    # Define the classes (assuming your dataset has a 'classes' attribute)\n","    classes = data_loader.dataset.classes\n","\n","    # Display images from the random batch in a grid\n","    num_images_to_show = min(5, len(images))  # Display at most 5 images\n","    fig, axes = plt.subplots(1, num_images_to_show, figsize=(15, 3))\n","\n","    for i in range(num_images_to_show):\n","        image = images[i]\n","        label = labels[i].item()\n","        class_name = classes[label]\n","\n","        # Show the image\n","        image = denormalize_and_clip(image, mean, std)  # Apply denormalization\n","        axes[i].imshow(image)\n","        axes[i].set_title(f'Class: {class_name}')\n","        axes[i].axis('off')  # Remove ticks and axes\n","\n","    plt.suptitle(f'{loader_type} Random Batch')\n","    plt.show()\n","\n","# Example usage with your dataloaders\n","mean = np.array([0.485, 0.456, 0.406])\n","std = np.array([0.229, 0.224, 0.225])\n","\n","visualize_random_batch(train_loader, 'Train Loader', mean, std)  # Visualization of a random batch from the training set\n","visualize_random_batch(val_loader, 'Validation Loader', mean, std)  # Visualization of a random batch from the validation set\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hOJrXSj5-w-J"},"outputs":[],"source":["# swapping out the resnet classifier head\n","\n","# using the function 'manual_seed()' created above to lock reproducibility of this cell\n","manual_seed()\n","\n","# freezing out the complete network first\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","# now swapping out the MLP classifier head\n","model.fc = nn.Sequential(nn.Linear(512, HIDDEN_LAYER_1),\n","                         nn.ReLU(),\n","                         nn.Dropout(p=0.2),\n","                         nn.Linear(HIDDEN_LAYER_1, HIDDEN_LAYER_2),\n","                         nn.ReLU(),\n","                         nn.Dropout(p=0.2),\n","                         nn.Linear(HIDDEN_LAYER_2, len(train_dataset.classes)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1707467397475,"user":{"displayName":"Sujatha","userId":"02387936916712154920"},"user_tz":-330},"id":"eZaISVQ--xGf","outputId":"8f7bc870-4a7b-460a-fb8f-b4a84e9a1196"},"outputs":[{"data":{"text/plain":["================================================================================================================================================================\n","Layer (type (var_name))                  Input Shape          Output Shape         Param #              Kernel Shape         Mult-Adds            Trainable\n","================================================================================================================================================================\n","ResNet (ResNet)                          [1, 3, 224, 224]     [1, 102]             --                   --                   --                   Partial\n","├─Conv2d (conv1)                         [1, 3, 224, 224]     [1, 64, 112, 112]    (9,408)              [7, 7]               118,013,952          False\n","├─BatchNorm2d (bn1)                      [1, 64, 112, 112]    [1, 64, 112, 112]    (128)                --                   128                  False\n","├─ReLU (relu)                            [1, 64, 112, 112]    [1, 64, 112, 112]    --                   --                   --                   --\n","├─MaxPool2d (maxpool)                    [1, 64, 112, 112]    [1, 64, 56, 56]      --                   3                    --                   --\n","├─Sequential (layer1)                    [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --                   --                   False\n","│    └─BasicBlock (0)                    [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --                   --                   False\n","│    │    └─Conv2d (conv1)               [1, 64, 56, 56]      [1, 64, 56, 56]      (36,864)             [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]      [1, 64, 56, 56]      (128)                --                   128                  False\n","│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 64, 56, 56]      [1, 64, 56, 56]      (36,864)             [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]      [1, 64, 56, 56]      (128)                --                   128                  False\n","│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --                   --                   --\n","│    └─BasicBlock (1)                    [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --                   --                   False\n","│    │    └─Conv2d (conv1)               [1, 64, 56, 56]      [1, 64, 56, 56]      (36,864)             [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]      [1, 64, 56, 56]      (128)                --                   128                  False\n","│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 64, 56, 56]      [1, 64, 56, 56]      (36,864)             [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]      [1, 64, 56, 56]      (128)                --                   128                  False\n","│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --                   --                   --\n","│    └─BasicBlock (2)                    [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --                   --                   False\n","│    │    └─Conv2d (conv1)               [1, 64, 56, 56]      [1, 64, 56, 56]      (36,864)             [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]      [1, 64, 56, 56]      (128)                --                   128                  False\n","│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 64, 56, 56]      [1, 64, 56, 56]      (36,864)             [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]      [1, 64, 56, 56]      (128)                --                   128                  False\n","│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --                   --                   --\n","├─Sequential (layer2)                    [1, 64, 56, 56]      [1, 128, 28, 28]     --                   --                   --                   False\n","│    └─BasicBlock (0)                    [1, 64, 56, 56]      [1, 128, 28, 28]     --                   --                   --                   False\n","│    │    └─Conv2d (conv1)               [1, 64, 56, 56]      [1, 128, 28, 28]     (73,728)             [3, 3]               57,802,752           False\n","│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]     [1, 128, 28, 28]     (256)                --                   256                  False\n","│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 128, 28, 28]     [1, 128, 28, 28]     (147,456)            [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]     [1, 128, 28, 28]     (256)                --                   256                  False\n","│    │    └─Sequential (downsample)      [1, 64, 56, 56]      [1, 128, 28, 28]     (8,448)              --                   6,422,784            False\n","│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --                   --                   --\n","│    └─BasicBlock (1)                    [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --                   --                   False\n","│    │    └─Conv2d (conv1)               [1, 128, 28, 28]     [1, 128, 28, 28]     (147,456)            [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]     [1, 128, 28, 28]     (256)                --                   256                  False\n","│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 128, 28, 28]     [1, 128, 28, 28]     (147,456)            [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]     [1, 128, 28, 28]     (256)                --                   256                  False\n","│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --                   --                   --\n","│    └─BasicBlock (2)                    [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --                   --                   False\n","│    │    └─Conv2d (conv1)               [1, 128, 28, 28]     [1, 128, 28, 28]     (147,456)            [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]     [1, 128, 28, 28]     (256)                --                   256                  False\n","│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 128, 28, 28]     [1, 128, 28, 28]     (147,456)            [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]     [1, 128, 28, 28]     (256)                --                   256                  False\n","│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --                   --                   --\n","│    └─BasicBlock (3)                    [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --                   --                   False\n","│    │    └─Conv2d (conv1)               [1, 128, 28, 28]     [1, 128, 28, 28]     (147,456)            [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]     [1, 128, 28, 28]     (256)                --                   256                  False\n","│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 128, 28, 28]     [1, 128, 28, 28]     (147,456)            [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]     [1, 128, 28, 28]     (256)                --                   256                  False\n","│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --                   --                   --\n","├─Sequential (layer3)                    [1, 128, 28, 28]     [1, 256, 14, 14]     --                   --                   --                   False\n","│    └─BasicBlock (0)                    [1, 128, 28, 28]     [1, 256, 14, 14]     --                   --                   --                   False\n","│    │    └─Conv2d (conv1)               [1, 128, 28, 28]     [1, 256, 14, 14]     (294,912)            [3, 3]               57,802,752           False\n","│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                --                   512                  False\n","│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 256, 14, 14]     [1, 256, 14, 14]     (589,824)            [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                --                   512                  False\n","│    │    └─Sequential (downsample)      [1, 128, 28, 28]     [1, 256, 14, 14]     (33,280)             --                   6,423,040            False\n","│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   --\n","│    └─BasicBlock (1)                    [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   False\n","│    │    └─Conv2d (conv1)               [1, 256, 14, 14]     [1, 256, 14, 14]     (589,824)            [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                --                   512                  False\n","│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 256, 14, 14]     [1, 256, 14, 14]     (589,824)            [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                --                   512                  False\n","│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   --\n","│    └─BasicBlock (2)                    [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   False\n","│    │    └─Conv2d (conv1)               [1, 256, 14, 14]     [1, 256, 14, 14]     (589,824)            [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                --                   512                  False\n","│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 256, 14, 14]     [1, 256, 14, 14]     (589,824)            [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                --                   512                  False\n","│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   --\n","│    └─BasicBlock (3)                    [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   False\n","│    │    └─Conv2d (conv1)               [1, 256, 14, 14]     [1, 256, 14, 14]     (589,824)            [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                --                   512                  False\n","│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 256, 14, 14]     [1, 256, 14, 14]     (589,824)            [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                --                   512                  False\n","│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   --\n","│    └─BasicBlock (4)                    [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   False\n","│    │    └─Conv2d (conv1)               [1, 256, 14, 14]     [1, 256, 14, 14]     (589,824)            [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                --                   512                  False\n","│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 256, 14, 14]     [1, 256, 14, 14]     (589,824)            [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                --                   512                  False\n","│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   --\n","│    └─BasicBlock (5)                    [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   False\n","│    │    └─Conv2d (conv1)               [1, 256, 14, 14]     [1, 256, 14, 14]     (589,824)            [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                --                   512                  False\n","│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 256, 14, 14]     [1, 256, 14, 14]     (589,824)            [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                --                   512                  False\n","│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --                   --                   --\n","├─Sequential (layer4)                    [1, 256, 14, 14]     [1, 512, 7, 7]       --                   --                   --                   False\n","│    └─BasicBlock (0)                    [1, 256, 14, 14]     [1, 512, 7, 7]       --                   --                   --                   False\n","│    │    └─Conv2d (conv1)               [1, 256, 14, 14]     [1, 512, 7, 7]       (1,179,648)          [3, 3]               57,802,752           False\n","│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]       [1, 512, 7, 7]       (1,024)              --                   1,024                False\n","│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 512, 7, 7]       [1, 512, 7, 7]       (2,359,296)          [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]       [1, 512, 7, 7]       (1,024)              --                   1,024                False\n","│    │    └─Sequential (downsample)      [1, 256, 14, 14]     [1, 512, 7, 7]       (132,096)            --                   6,423,552            False\n","│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --                   --                   --\n","│    └─BasicBlock (1)                    [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --                   --                   False\n","│    │    └─Conv2d (conv1)               [1, 512, 7, 7]       [1, 512, 7, 7]       (2,359,296)          [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]       [1, 512, 7, 7]       (1,024)              --                   1,024                False\n","│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 512, 7, 7]       [1, 512, 7, 7]       (2,359,296)          [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]       [1, 512, 7, 7]       (1,024)              --                   1,024                False\n","│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --                   --                   --\n","│    └─BasicBlock (2)                    [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --                   --                   False\n","│    │    └─Conv2d (conv1)               [1, 512, 7, 7]       [1, 512, 7, 7]       (2,359,296)          [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]       [1, 512, 7, 7]       (1,024)              --                   1,024                False\n","│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --                   --                   --\n","│    │    └─Conv2d (conv2)               [1, 512, 7, 7]       [1, 512, 7, 7]       (2,359,296)          [3, 3]               115,605,504          False\n","│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]       [1, 512, 7, 7]       (1,024)              --                   1,024                False\n","│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --                   --                   --\n","├─AdaptiveAvgPool2d (avgpool)            [1, 512, 7, 7]       [1, 512, 1, 1]       --                   --                   --                   --\n","├─Sequential (fc)                        [1, 512]             [1, 102]             --                   --                   --                   True\n","│    └─Linear (0)                        [1, 512]             [1, 256]             131,328              --                   131,328              True\n","│    └─ReLU (1)                          [1, 256]             [1, 256]             --                   --                   --                   --\n","│    └─Dropout (2)                       [1, 256]             [1, 256]             --                   --                   --                   --\n","│    └─Linear (3)                        [1, 256]             [1, 128]             32,896               --                   32,896               True\n","│    └─ReLU (4)                          [1, 128]             [1, 128]             --                   --                   --                   --\n","│    └─Dropout (5)                       [1, 128]             [1, 128]             --                   --                   --                   --\n","│    └─Linear (6)                        [1, 128]             [1, 102]             13,158               --                   13,158               True\n","================================================================================================================================================================\n","Total params: 21,462,054\n","Trainable params: 177,382\n","Non-trainable params: 21,284,672\n","Total mult-adds (G): 3.66\n","================================================================================================================================================================\n","Input size (MB): 0.60\n","Forward/backward pass size (MB): 59.81\n","Params size (MB): 85.85\n","Estimated Total Size (MB): 146.26\n","================================================================================================================================================================"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["# checking details after freezing the convolution backbone and swapping out the classifier head\n","\n","summary(model,\n","        input_size=(1,3,224,224),\n","        col_names=(\"input_size\",\n","                   \"output_size\",\n","                   \"num_params\",\n","                   \"kernel_size\",\n","                   \"mult_adds\",\n","                   \"trainable\"),\n","        col_width=20,\n","        row_settings=(\"var_names\",))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J7vb4Pm2I9RB"},"outputs":[],"source":["# creating a single step of training\n","\n","def training_step(model: nn.Module,\n","                  train_dataloader: torch.utils.data.DataLoader,\n","                  optimizer: torch.optim.Optimizer,\n","                  criterion: nn.Module,\n","                  training_accuracy: MulticlassAccuracy,\n","                  training_f1: MulticlassF1Score,\n","                  epoch_num: int,\n","                  device: torch.device = device) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n","    '''\n","    Function for a single step of training.\n","\n","    Args:\n","        model: The model/network to train\n","        train_dataloader: The dataloader for training set\n","        optimizer: The optimization algorithm to use\n","        criterion: The error function for setting up the optimization problem\n","        training_accuracy: Instance of MulticlassAccuracy class from torchmetrics\n","        training_f1: Instance of MulticlassF1Score class from torchmetrics\n","        epoch_num: The current epoch number\n","        device: The device being used for model/network training [Default: device]\n","\n","    Returns:\n","        Tuple of training loss, training accuracy and training f1 score\n","    '''\n","\n","    # setting the model to train mode\n","    model.train()\n","\n","    # placeholder for calculating loss epoch wise\n","    epoch_loss = 0\n","\n","    # using tqdm for progress bar\n","    with tqdm(enumerate(train_dataloader, start=1), total=len(train_dataloader), unit=\" train-batch\") as tepoch:\n","        # iterating over the data batches\n","        for batch_idx, (features, labels) in tepoch:\n","            # setting description (prefix) for tqdm progress bar\n","            tepoch.set_description(f\"Epoch: {epoch_num+1} | Phase - Training\")\n","\n","            # moving the batches to device\n","            features, labels = features.to(device), labels.to(device).type(torch.long)      # typecasting labels (if using CE Loss)\n","\n","            # doing forward propagation\n","            logits = model(features)\n","            # calculating loss\n","            loss = criterion(logits, labels)\n","            # zeroing out accumulated gradients from the previous iteration\n","            optimizer.zero_grad()\n","            # doing backpropagation: computing partial derivatives\n","            loss.backward()\n","            # taking an optimization step using the gradients computed above\n","            optimizer.step()\n","\n","            # calculating average loss and Accuracy/F1-Score per batch (removing this part from computation graph)\n","            with torch.inference_mode():        # use torch.no_grad() if torch.inference_mode() is not available in PyTorch version\n","                avg_loss_sample = loss/len(labels)\n","                batch_acc = training_accuracy.forward(logits, labels)\n","                batch_f1 = training_f1.forward(logits, labels)\n","\n","            # accumulating in epoch loss\n","            epoch_loss += avg_loss_sample\n","\n","            # setting postfix for progress bar\n","            tepoch.set_postfix(batch_f1_score=batch_f1.item(), batch_accuracy=f\"{batch_acc.item()*100:.2f}%\", loss_per_sample=avg_loss_sample.item())\n","\n","    # averaging loss over batches\n","    epoch_loss /= len(train_dataloader)\n","\n","    # for readability\n","    print()\n","\n","    # printing epoch statistics\n","    print(f\"[INFO] Epoch: {epoch_num+1} | loss: {epoch_loss.item():.3f} | training acc: {training_accuracy.compute().item()*100:.2f}% | training f1-score: {training_f1.compute().item():.2f}\")\n","\n","    # returning loss, acc and f1\n","    return epoch_loss, training_accuracy.compute(), training_f1.compute()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vSQchjpjI9T_"},"outputs":[],"source":["# creating a single step of testing\n","\n","def testing_step(model: nn.Module,\n","                 test_dataloader: torch.utils.data.DataLoader,\n","                 criterion: nn.Module,\n","                 test_accuracy: MulticlassAccuracy,\n","                 test_f1: MulticlassF1Score,\n","                 epoch_num: int = -1,\n","                 device: torch.device = device) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n","    '''\n","    Function for a single step of testing.\n","\n","    Args:\n","        model: The model/network to train\n","        test_dataloader: The dataloader for test set\n","        criterion: The error function for quantifying how wrong predictions are\n","        test_accuracy: Instance of MulticlassAccuracy class from torchmetrics\n","        test_f1: Instance of MulticlassF1Score class from torchmetrics\n","        epoch_num: The current epoch number [Default: -1]\n","        device: The device being used for model/network testing [Default: device]\n","\n","    Returns:\n","        Tuple of test loss, test accuracy and test f1 score\n","    '''\n","\n","    # setting the model to eval mode\n","    model.eval()\n","\n","    # placeholder for calculating loss epoch wise\n","    epoch_loss = 0\n","\n","    # using tqdm for progress bar\n","    with tqdm(enumerate(test_dataloader, start=1), total=len(test_dataloader), unit=\" test-batch\") as tepoch:\n","        # iterating over the data batches\n","        for batch_idx, (features, labels) in tepoch:\n","            # setting description (prefix) for tqdm progress bar\n","            tepoch.set_description(f\"Epoch: {epoch_num+1} | Phase - Validation/Test\")\n","\n","            # moving the batches to device\n","            features, labels = features.to(device), labels.to(device).type(torch.long)      # typecasting labels (if using CE Loss)\n","\n","            # doing forward poss + loss computation, calculating average loss and Accuracy/F1-Score per batch (removing this part from computation graph)\n","            with torch.inference_mode():        # use torch.no_grad() if torch.inference_mode() is not available in PyTorch version\n","                # doing forward propagation\n","                logits = model(features)\n","                # calculating loss\n","                loss = criterion(logits, labels)\n","                # calculating per sample loss in a batch\n","                avg_loss_sample = loss/len(labels)\n","                # calculating accuracy for the batch\n","                batch_acc = test_accuracy.forward(logits, labels)\n","                # calculating f1-score for the batch\n","                batch_f1 = test_f1.forward(logits, labels)\n","\n","            # accumulating in epoch loss\n","            epoch_loss += avg_loss_sample\n","\n","            # setting postfix for progress bar\n","            tepoch.set_postfix(batch_f1_score=batch_f1.item(), batch_accuracy=f\"{batch_acc.item()*100:.2f}%\", loss_per_sample=avg_loss_sample.item())\n","\n","    # averaging loss over batches\n","    epoch_loss /= len(test_dataloader)\n","\n","    # for readability\n","    print()\n","\n","    # printing epoch statistics\n","    print(f\"[INFO] Epoch: {epoch_num+1} | loss: {epoch_loss.item():.3f} | val/test acc: {test_accuracy.compute().item()*100:.2f}% | val/test f1-score: {test_f1.compute().item():.2f}\")\n","\n","    # for readability\n","    print()\n","\n","    # returning loss, acc and f1\n","    return epoch_loss, test_accuracy.compute(), test_f1.compute()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H54gwAEII9Wt"},"outputs":[],"source":["# decorating function for training function below\n","\n","def timing_function(func: Callable[..., Any]) -> Callable[..., Any]:\n","    '''\n","    Decorating function for determining the time taken for execution of a function.\n","\n","    Args:\n","        func: Function whose execution time has to be determined\n","\n","    Returns:\n","        wrapper function around the function whose execution time we have to determine\n","    '''\n","\n","    # using wraps to preserve function signature\n","    @functools.wraps(func)\n","    def wrapper(*args, **kwargs) -> Any:\n","        '''\n","        The wrapper function wrapping the function that was input to timing_function.\n","\n","        Args:\n","            *args: Variable length positional argument(s)\n","            *kwargs: Variable length keyword argument(s)\n","\n","        Returns:\n","            Any output received from the 'func' function\n","        '''\n","\n","        # computing time taken for execution of function (training pipeline etc.)\n","        start_time = time.perf_counter()\n","        func_out = func(*args, **kwargs)\n","        end_time = time.perf_counter()\n","\n","        # for readability\n","        print()\n","        print()\n","\n","        # printing time statistics\n","        print(f\"[INFO] Time taken -> {(end_time-start_time)//60}m and {(end_time-start_time)%60:.2f}s\")\n","\n","        # return statement for wrapper\n","        return func_out\n","    # returning wrapper\n","    return wrapper"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MzLaoctqI9Zj"},"outputs":[],"source":["# training pipeline: combining the two functions training_step and testing_step\n","\n","@timing_function\n","def training(model: nn.Module,\n","             train_dataloader: torch.utils.data.DataLoader,\n","             test_dataloader: torch.utils.data.DataLoader,\n","             optimizer: torch.optim.Optimizer,\n","             criterion: nn.Module,\n","             training_accuracy: MulticlassAccuracy,\n","             training_f1: MulticlassF1Score,\n","             test_accuracy: MulticlassAccuracy,\n","             test_f1: MulticlassF1Score,\n","             epochs: int = 5,\n","             device: torch.device = device) -> Tuple[dict, dict]:\n","             '''\n","             Function defining the training pipeline.\n","\n","             Args:\n","                 model: The model/network to train\n","                 train_dataloader: The dataloader for training set\n","                 test_dataloader: The dataloader for test set\n","                 optimizer: The optimization algorithm to use\n","                 criterion: The error function for setting up the optimization problem\n","                 training_accuracy: Instance of MulticlassAccuracy class from torchmetrics (for training)\n","                 training_f1: Instance of MulticlassF1Score class from torchmetrics (for training)\n","                 test_accuracy: Instance of MulticlassAccuracy class from torchmetrics (for test)\n","                 test_f1: Instance of MulticlassF1Score class from torchmetrics (for test)\n","                 epochs: The number of epochs to train the model for [Default: 5]\n","                 device: The device being used for model/network training + eval [Default: device]\n","\n","             Returns:\n","                 None\n","             '''\n","\n","             # moving model to device\n","             model.to(device)\n","\n","             # moving torchmetrics metric objects to device\n","             training_accuracy.to(device)\n","             training_f1.to(device)\n","             test_accuracy.to(device)\n","             test_f1.to(device)\n","\n","             # lists for tracking loss and metrics\n","             train_loss = []\n","             train_acc = []\n","             train_f1 = []\n","             val_loss = []\n","             val_acc = []\n","             val_f1 = []\n","\n","             # will be used for keeping track of best performing model\n","             best_loss = float(\"inf\")\n","\n","             # training model for given number of epochs\n","             for epoch_iter in range(epochs):\n","                # single step of training\n","                train_epoch_loss, train_epoch_acc, train_epoch_f1 = training_step(model,\n","                                                                                  train_dataloader,\n","                                                                                  optimizer,\n","                                                                                  criterion,\n","                                                                                  training_accuracy,\n","                                                                                  training_f1,\n","                                                                                  epoch_iter,\n","                                                                                  device)\n","                # appending to respective lists (train)\n","                train_loss.append(train_epoch_loss)\n","                train_acc.append(train_epoch_acc)\n","                train_f1.append(train_epoch_f1)\n","\n","                # for readability\n","                print()\n","\n","                # single step of validation\n","                val_epoch_loss, val_epoch_acc, val_epoch_f1 = testing_step(model,\n","                                                                           test_dataloader,\n","                                                                           criterion,\n","                                                                           test_accuracy,\n","                                                                           test_f1,\n","                                                                           epoch_iter,\n","                                                                           device)\n","                # appending to respective lists (test)\n","                val_loss.append(val_epoch_loss)\n","                val_acc.append(val_epoch_acc)\n","                val_f1.append(val_epoch_f1)\n","\n","                # for readability\n","                print()\n","\n","                # checking if loss has improved\n","                if best_loss > val_epoch_loss:\n","                    best_model = copy.deepcopy(model.state_dict())       # taking a deepcopy of model.state_dict()\n","                    best_loss = val_epoch_loss\n","                    best_epoch = epoch_iter\n","\n","             # using list comprehension for loss, acc and f1 lists\n","             train_loss = [tensor.item() for tensor in train_loss]\n","             train_acc = [tensor.item() for tensor in train_acc]\n","             train_f1 = [tensor.item() for tensor in train_f1]\n","             val_loss = [tensor.item() for tensor in val_loss]\n","             val_acc = [tensor.item() for tensor in val_acc]\n","             val_f1 = [tensor.item() for tensor in val_f1]\n","\n","             # creating training statistics dictionary\n","             training_statistics = {\"training_loss\": train_loss,\n","                                    \"training_accuracy\": train_acc,\n","                                    \"training_f1\": train_f1,\n","                                    \"validation_loss\": val_loss,\n","                                    \"validation_accuracy\": val_acc,\n","                                    \"validation_f1\": val_f1,\n","                                    \"best_epoch\": best_epoch+1,\n","                                    \"loss_on_best_epoch\": best_loss.item(),\n","                                    \"device_used\": device}\n","\n","             # for readability\n","             print()\n","             print()\n","\n","             # printing training statistics\n","             print(f\"Best epoch: {training_statistics['best_epoch']} | Training acc on best epoch: {training_statistics['training_accuracy'][training_statistics['best_epoch']-1]*100:.2f}% | Validation acc on best epoch: {training_statistics['validation_accuracy'][training_statistics['best_epoch']-1]*100:.2f}%\")\n","\n","             # returning best performing model and statistics dictionary\n","             return best_model, training_statistics\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mLv-yGooJIKs"},"outputs":[],"source":["# for saving and loading model\n","\n","# saving model\n","def save_model(model: nn.Module,\n","               model_name: str) -> str:\n","    '''\n","    Function for saving state_dict of model.\n","\n","    Args:\n","        model: model (nn.Module) whose state_dict you have to save\n","        model_name: The name to use for saving the state_dict\n","\n","    Returns:\n","        The path to saved state_dict (str)\n","    '''\n","\n","    # model save location\n","    SAVE_PATH = f\"./{model_name}.pt\"\n","\n","    # saving model and printing message\n","    torch.save(model.state_dict(), SAVE_PATH)\n","    print(f\"[INFO] {model_name} saved to {SAVE_PATH}\")\n","\n","    # returning path of saved model\n","    return SAVE_PATH\n","\n","# saving general checkpoint\n","def save_checkpoint(optimizer: torch.optim.Optimizer,\n","                    criterion: nn.Module,\n","                    epoch: int,\n","                    device_trained_on: torch.device,\n","                    hidden_layers: tuple,\n","                    output_layer: int,\n","                    classes: list,\n","                    class_to_idx: dict,\n","                    checkpoint_name: str = \"checkpoint\") -> str:\n","    '''\n","    Function for saving the general checkpoint including anything important other than state_dict() of model.\n","\n","    Args:\n","        optimizer: optimizer whose state_dict has to be saved\n","        criterion: loss/criterion used for training the network\n","        epoch: The epoch number of best performing model\n","        device_trained_on: The device on which the model was trained on\n","        hidden_layers: The specifications of the two hidden layers\n","        classes: The list of classes for the given classification problem\n","        class_to_idx: The class to index mapping/dictionary\n","        dheckpoint_name: The name by which to save the general checkpoint\n","\n","    Returns:\n","        The path to saved general checkpoint (str)\n","    '''\n","\n","    # checkpoint save location\n","    SAVE_PATH = f\"./{checkpoint_name}.pth\"\n","\n","    # saving the checkpoint\n","    torch.save({\"optimizer\": optimizer.state_dict(),\n","                \"criterion\": criterion,\n","                \"epoch\": epoch,\n","                \"device_trained_on\": device_trained_on,\n","                \"hidden_layers\": hidden_layers,\n","                \"output_layer\": output_layer,\n","                \"classes\": classes,\n","                \"class_to_idx\": class_to_idx}, SAVE_PATH)\n","\n","    # printing save confirmation\n","    print(f\"[INFO] The general checkpoint has been saved to: {SAVE_PATH}\")\n","\n","    # returning the saved checkpoint path\n","    return SAVE_PATH\n","\n","# loading model\n","def load_model(model_save_path: str,\n","               hidden_layers: tuple,\n","               output_layer: int,\n","               device_trained_on: torch.device,\n","               device: torch.device) -> nn.Module:\n","    '''\n","    Function for loading state_dict() of the saved model and inserting that into a newly defined architecture (must be same as original model arch).\n","\n","    Args:\n","        model_save_path: Save path to the state_dict() of model\n","        hidden_layers: The specifications of the two hidden layers\n","        output_layer: The specification of the output layer\n","        device_trained_on: The device on which the model was trained on originally\n","        device: The device on which the newly defined model should be moved to\n","\n","    Returns:\n","        The model with loaded state_dict()\n","    '''\n","\n","    # building resnet\n","    model = torchvision.models.resnet34(weights = None)\n","\n","    # swapping classifier head using hidden layers\n","    model.fc = nn.Sequential(nn.Linear(512, hidden_layers[0]),\n","                             nn.ReLU(),\n","                             nn.Dropout(p=0.2),\n","                             nn.Linear(hidden_layers[0], hidden_layers[1]),\n","                             nn.ReLU(),\n","                             nn.Dropout(p=0.2),\n","                             nn.Linear(hidden_layers[1], output_layer))\n","\n","    # loading model state_dict\n","    if str(device_trained_on) in (\"cuda\", \"cuda:0\"):\n","        # saved on GPU, loading on CPU case\n","        if str(device) == \"cpu\":\n","            model.load_state_dict(torch.load(model_save_path, map_location=device))\n","        # saved on GPU, loading on GPU case\n","        elif str(device) in (\"cuda\", \"cuda:0\"):\n","            model.load_state_dict(torch.load(model_save_path))\n","    else:\n","        # saved on CPU, loading on CPU case\n","        if str(device) == \"cpu\":\n","            model.load_state_dict(torch.load(model_save_path))\n","        # saved on CPU, loading on GPU case\n","        elif str(device) in (\"cuda\", \"cuda:0\"):\n","            model.load_state_dict(torch.load(model_save_path, map_location=\"cuda:0\"))\n","\n","    # moving model to device and switching to eval mode\n","    model.to(device);\n","    model.eval();\n","\n","    # returning model\n","    return model\n","\n","# loading model\n","def load_checkpoint(checkpoint_save_path: str) -> dict:\n","    '''\n","    Function for loading checkpoint dictionary from given path of the saved checkpoint.\n","\n","    Args:\n","        checkpoint_save_path: Path to the general checkpoint .pth file\n","\n","    Returns:\n","        The checkpoint dictionary (dict)\n","    '''\n","\n","    # returning checkpoint dictionary\n","    CHECKPOINT_DICT = torch.load(checkpoint_save_path)\n","    return CHECKPOINT_DICT\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XfeP_RgjJINe"},"outputs":[],"source":["# creating criterion, optimizer and metrics\n","\n","# criterion and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.AdamW(model.fc.parameters(),        # change this to torch.optim.Adam\n","                             lr = LEARNING_RATE)\n","\n","# creating metrics to be used in training pipeline (for training and validation phase)\n","training_acc = MulticlassAccuracy(num_classes = NUM_CLASSES)\n","training_f1 = MulticlassF1Score(num_classes = NUM_CLASSES)\n","val_acc = MulticlassAccuracy(num_classes = NUM_CLASSES)\n","val_f1 = MulticlassF1Score(num_classes = NUM_CLASSES)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sgxJuCL0JIRD"},"outputs":[],"source":["# using manual_seed for reproducbility\n","manual_seed()\n","\n","# starting training\n","resnet_state_dict, training_stats = training(model,\n","                                             train_dataloader = train_loader,\n","                                             test_dataloader = val_loader,\n","                                             optimizer = optimizer,\n","                                             criterion = criterion,\n","                                             training_accuracy = training_acc,\n","                                             training_f1 = training_f1,\n","                                             test_accuracy = val_acc,\n","                                             test_f1 = val_f1,\n","                                             epochs=EPOCHS)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EsBb_i3CI9c_"},"outputs":[],"source":["# function to plot curves\n","\n","def plot_curves(stats):\n","    # Extract data from the dictionary\n","    training_loss = stats['training_loss']\n","    training_accuracy = stats['training_accuracy']\n","    training_f1 = stats['training_f1']\n","\n","    validation_loss = stats['validation_loss']\n","    validation_accuracy = stats['validation_accuracy']\n","    validation_f1 = stats['validation_f1']\n","\n","    best_epoch = stats['best_epoch']\n","    loss_on_best_epoch = stats['loss_on_best_epoch']\n","\n","    epochs = range(1, len(training_loss) + 1)\n","\n","    # Plotting loss curve\n","    plt.figure(figsize=(15, 5))\n","\n","    plt.subplot(1, 3, 1)\n","    plt.plot(epochs, training_loss, label='Training Loss')\n","    plt.plot(epochs, validation_loss, label='Validation Loss')\n","    plt.scatter(best_epoch, loss_on_best_epoch, color='darkred', marker='o', label='Best Epoch')\n","    plt.title('Loss Curves')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.xticks(epochs)  # Ensure x-axis ticks are integers\n","    plt.legend()\n","\n","    # Plotting accuracy curve\n","    plt.subplot(1, 3, 2)\n","    plt.plot(epochs, training_accuracy, label='Training Accuracy')\n","    plt.plot(epochs, validation_accuracy, label='Validation Accuracy')\n","    plt.title('Accuracy Curves')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.xticks(epochs)  # Ensure x-axis ticks are integers\n","    plt.legend()\n","\n","    # Plotting F1-score curve\n","    plt.subplot(1, 3, 3)\n","    plt.plot(epochs, training_f1, label='Training F1-score')\n","    plt.plot(epochs, validation_f1, label='Validation F1-score')\n","    plt.title('F1-score Curves')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('F1-score')\n","    plt.xticks(epochs)  # Ensure x-axis ticks are integers\n","    plt.legend()\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# displaying curves\n","plot_curves(training_stats)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F9X8iHaiJUaN"},"outputs":[],"source":["# saving model and checkpoint\n","MODEL_SAVE_PATH = save_model(model, \"resnet_34\")\n","CHKPT_SAVE_PATH = save_checkpoint(optimizer,\n","                                  criterion,\n","                                  epoch = training_stats[\"best_epoch\"]-1,\n","                                  device_trained_on = device,\n","                                  hidden_layers = (HIDDEN_LAYER_1, HIDDEN_LAYER_2),\n","                                  output_layer = NUM_CLASSES,\n","                                  classes = CLASSES,\n","                                  class_to_idx = CLASS_TO_IDX,\n","                                  checkpoint_name = \"checkpoint\")\n","\n","# loading model and checkpoint\n","CHKPT_DICT = load_checkpoint(CHKPT_SAVE_PATH)\n","new_model = load_model(MODEL_SAVE_PATH,\n","                       hidden_layers = CHKPT_DICT[\"hidden_layers\"],\n","                       output_layer = CHKPT_DICT[\"output_layer\"],\n","                       device_trained_on = CHKPT_DICT[\"device_trained_on\"],\n","                       device = torch.device(\"cpu\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3V1AHS9kJUds"},"outputs":[],"source":["# function to predict on a give image sample and draw a bargraph\n","\n","@timing_function\n","def predict_and_plot_topk(model: nn.Module,\n","                          img_transform: transforms.Compose,\n","                          class_list: list,\n","                          image_path: str,\n","                          device: torch.device,\n","                          topk: int = 5):\n","\n","    # Load and preprocess the image\n","    image = Image.open(image_path).convert(\"RGB\")\n","    input_tensor = img_transform(image)\n","    input_batch = input_tensor.unsqueeze(0).to(device)\n","\n","    # Moving model to device and switching to eval mode\n","    model.to(device)\n","    model.eval()\n","\n","    # Make predictions\n","    with torch.inference_mode():\n","        output = model(input_batch)\n","\n","    # Convert the output to probabilities using softmax\n","    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n","\n","    # Get the top-k class indices and probabilities\n","    topk_probs, topk_indices = torch.topk(probabilities, topk)\n","    topk_probs_np = topk_probs.numpy(force=True)\n","    topk_indices_np = topk_indices.numpy(force=True)\n","\n","    # Convert tensor to numpy array for plotting\n","    probs_np = probabilities.numpy(force=True)\n","\n","    # Create a horizontal bar graph\n","    plt.figure(figsize=(10, 6))\n","\n","    # Plot the image\n","    plt.subplot(2, 1, 1)\n","    plt.imshow(image)\n","    plt.title('Input Image')\n","    plt.axis('off')\n","\n","    # Plot the top-k classes\n","    plt.subplot(2, 1, 2)\n","    plt.barh([class_list[i] for i in topk_indices_np], topk_probs_np, color='blue')\n","    plt.xlabel('Predicted Probability')\n","    plt.title(f'Top-{topk} Predicted Classes')\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# downloading a sample image\n","!wget https://i.ytimg.com/vi/tXjHb5QmDV0/maxresdefault.jpg -O /content/image.jpg      # provide link to any .jpg image here\n","\n","# Example usage\n","# Assuming you have a PyTorch model 'new_model', a list of class names extracted using dataset_name.classes, and an image file path\n","predict_and_plot_topk(new_model,\n","                      resnet_34_default_transforms,\n","                      CLASSES,\n","                      \"/content/image.jpg\",\n","                      device,\n","                      topk=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"foZUVsVcJUlJ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPNhLtGhyX3lCs+yxgv3x5n","gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
